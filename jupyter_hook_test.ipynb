{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  AutoTokenizer, OPTForCausalLM, set_seed, AutoModel\n",
    "import torch\n",
    "import time\n",
    "from prompt import build_prompt, get_prompt_templates, get_prompt_templates_withtype, build_prompt_on_type, get_prompt_templates_industry, build_prompt_on_industry\n",
    "from utils import filter_unfinished_output, filter_length_token, filter_length_sentence, select_selling_point, first_token_upper\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "\n",
    "bytedrive = '/mnt/bn/lq-lby-bytenas-aigc/opt_model/'\n",
    "config_path = 'config_30B'\n",
    "device = 'cuda'\n",
    "templates_path = '/mnt/bn/lq-lby-bytenas-aigc/hook_generation/data/templates.txt'\n",
    "templates_withtype_path = '/mnt/bn/lq-lby-bytenas-aigc/hook_generation/data/templates_withtype.txt'\n",
    "templates_sp_path = '/mnt/bn/lq-lby-bytenas-aigc/hook_generation/data/hook_templates_product_sps_indu_hook_type.txt'\n",
    "\n",
    "s_time = time.time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(bytedrive + config_path, use_fast=False)\n",
    "model = OPTForCausalLM.from_pretrained(bytedrive + config_path, torch_dtype=torch.float16, device_map='auto')\n",
    "print('======loading model used time:', time.time() - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt import build_prompt, get_prompt_templates, get_prompt_templates_withtype, build_prompt_on_type, get_prompt_templates_industry, build_prompt_on_industry\n",
    "from utils import filter_unfinished_output, filter_length_token, filter_length_sentence, select_selling_point, first_token_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a hook for product based on selling point.\\n\\\n",
    "product:Coffee; selling points: quick and fast, tasty =>This is a must-have if you cannot live without coffee, especially if your time in the morning is tight, you need to watch this!\\n\\\n",
    "product: Shake powder; selling points: provide all proteins and nutrients, taste good, many flavors =>I don't know about you, but I have been searching for so many products to finally find a proper protein shake. \\n\\\n",
    "product: Cheesecake; selling points: low fat and sugar free, delicious, smooth, creamy, $10 =>Who says you can't have cheesecake on my diet? I highly recommend this cheesecake.\\n\"\n",
    "\n",
    "\n",
    "prompt_no_sps = \"Write a hook for product based on selling point.\\n\\\n",
    "product:Coffee; selling points: =>This is a must-have if you cannot live without coffee, especially if your time in the morning is tight, you need to watch this!\\n\\\n",
    "product: Shake powder; selling points: =>I don't know about you, but I have been searching for so many products to finally find a proper protein shake. \\n\\\n",
    "product: Cheesecake; selling points: =>Who says you can't have cheesecake on my diet? I highly recommend this cheesecake.\\n\"\n",
    "\n",
    "\n",
    "\n",
    "prompt_test = \"Write a refined ad hook for product considering selling points.\\n\\\n",
    "product: maltesers; selling point: crunchy, chewy =>Maltesers are a must if you want a delicious chocolate treat.\\n\\\n",
    "product: Meal kit; selling point: fast and easy, nutritious =>Guys guess what I found for you! Only $10 for a meal, but very healthy and quick. Do you believe it?\\n\\\n",
    "product: Chamomile Tea; selling point: no added sugar, contained ginger and chamoile =>Need to calm yourself before going to bed? Try this amazing chamomile tea!\\n\\\n",
    "product: Goldfish Crackers; selling point: crunchy, always baked never fried =>\"\n",
    "\n",
    "prompt_test = \"Write a refined ad hook for product considering selling points.\\n\\\n",
    "Product: Pushup Bra\\n\\\n",
    "Selling points: \\n\\\n",
    "=>Hey girls have you ever experienced back rolls, side spillage, and irritating strapsï¼ŸThis bra can help you solve those problems.\\n\\\n",
    "Product: Men's suit\\n\\\n",
    "Selling points: \\n\\\n",
    "=>Here are 3 mistakes a guy makes.\\n\\\n",
    "Product: Hoodies\\n\\\n",
    "Selling points: \\n\\\n",
    "=>Are you having a hard time to find something comfortable and pretty at the same time to wear at home?\\n\\\n",
    "Product: Denim jeans\\n\\\n",
    "Selling points: \\n\\\n",
    "=>Hey bro, do you know you can style jeans with different tops to wear on all occasions?\\n\\\n",
    "Product: Light Scarf\\n\\\n",
    "Selling points: \\n\\\n",
    "=>\"\n",
    "\n",
    "# product = 'Peanut Butter'\n",
    "# sps = ''\n",
    "# inputs = prompt_no_sps + 'product: {}; selling points:{} =>'.format(product, sps.lower())\n",
    "inputs = prompt_test\n",
    "print(inputs)\n",
    "input_ids = tokenizer(inputs, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_length = len(tokenizer.batch_decode(input_ids, skip_special_tokens=True)[0])\n",
    "print(len(inputs), prompt_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "# set_seed(777)\n",
    "generated_ids = model.generate(input_ids, max_length=input_ids.shape[1]+35, min_length=12+input_ids.shape[1], \\\n",
    "                                do_sample=True, top_k=30, top_p=0.8, temperature=0.8, \\\n",
    "                                pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id, \\\n",
    "                                no_repeat_ngram_size=3, remove_invalid_values = True, num_return_sequences=5)\n",
    "ori_gen_sent = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "gen_sent = [x[prompt_length:] for x in ori_gen_sent]\n",
    "gen_sent = [x.split('\\n')[0] for x in gen_sent]\n",
    "for each in gen_sent:\n",
    "    print(each)\n",
    "print(time.time() - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
